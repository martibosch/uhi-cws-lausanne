{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Official stations data\n",
    "\n",
    "In this notebook, we will assemble a time series of meteorological measurements from meteorological stations in the study region. We will follow these steps:\n",
    "1. Given a target year, use the Agrometeo API to select the temporal range of interest as the hottest heatwave, defined as follows: the hottest (based on mean temperature) period of at least 3 consecutive days with an average temperature over 27$^{\\circ}$C (namely, the hottest period of level 4 warning days [according to the heat warning level definitions by MeteoSwiss](https://www.meteoswiss.admin.ch/weather/weather-and-climate-from-a-to-z/heat-warnings.html)).\n",
    "2. Given the temporal range of interest obtained above, download the time series of meteorological measurements from the other official meteorological stations in the study region.\n",
    "3. Resample all data to hourly resolution, assemble into a single long data frame and dump into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from meteora import utils as meteora_utils\n",
    "from meteora.clients import AgrometeoClient\n",
    "from shapely import geometry\n",
    "\n",
    "from uhi_cws_lausanne import official_stations_utils, plot_utils\n",
    "\n",
    "figwidth, figheight = plt.rcParams[\"figure.figsize\"]\n",
    "\n",
    "HEATWAVE_N_CONSECUTIVE_DAYS = 3\n",
    "HEATWAVE_THRESHOLD = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# spatial extent\n",
    "agglom_extent_filepath = \"../data/raw/agglom-extent.gpkg\"\n",
    "\n",
    "# files to write\n",
    "dst_ts_df_filepath = \"../data/interim/official-ts-df.csv\"\n",
    "dst_stations_gdf_filepath = \"../data/interim/official-stations.gpkg\"\n",
    "\n",
    "# select study period\n",
    "start_year = 2021\n",
    "end_year = 2023\n",
    "# whether we want to include the days before and after the heatwave\n",
    "days_before = 1\n",
    "days_after = 1\n",
    "# months to consider when querying the Agrometeo API\n",
    "start_month = 5\n",
    "end_month = 9\n",
    "\n",
    "# S3 data\n",
    "bucket_name = \"ceat-data\"\n",
    "idaweb_key = \"meteoswiss/idaweb/lausanne-agglom-2022-2023.txt\"\n",
    "vaudair_key = \"vaud-air/VaudAir_AggloLausanne_20220101-20231231_20240613.xlsx\"\n",
    "\n",
    "# station locations\n",
    "station_location_filepath = (\n",
    "    \"https://zenodo.org/record/4384675/files/station-locations.csv\"\n",
    ")\n",
    "station_location_crs = \"epsg:2056\"\n",
    "\n",
    "# date format for heatwave labels\n",
    "STRFMT = \"%Y/%m/%d\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Select study period\n",
    "\n",
    "We will use the Agrometeo API to select the hottest heatwave period as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only land extent (agglom_extent_filepath has two geometries: land and lake)\n",
    "region = gpd.read_file(agglom_extent_filepath)[\"geometry\"].iloc[:1]\n",
    "\n",
    "# download data\n",
    "agrometeo_client = AgrometeoClient(region=region)\n",
    "agrometeo_ts_df = pd.concat(\n",
    "    [\n",
    "        agrometeo_client.get_ts_df(\n",
    "            \"temperature\",\n",
    "            datetime.date(year, start_month, 1),\n",
    "            datetime.date(year, end_month, 30),\n",
    "            scale=\"hour\",\n",
    "        )\n",
    "        for year in range(start_year, end_year + 1)\n",
    "    ],\n",
    "    axis=\"rows\",\n",
    ")\n",
    "# convert to wide form\n",
    "agrometeo_ts_df = meteora_utils.long_to_wide(agrometeo_ts_df)\n",
    "\n",
    "# find consecutive days above threshold\n",
    "day_mean_ts_ser = (\n",
    "    agrometeo_ts_df.groupby(agrometeo_ts_df.index.date).mean().mean(axis=\"columns\")\n",
    ")\n",
    "idx = (day_mean_ts_ser >= HEATWAVE_THRESHOLD).rolling(\n",
    "    window=HEATWAVE_N_CONSECUTIVE_DAYS, center=True\n",
    ").sum() >= HEATWAVE_N_CONSECUTIVE_DAYS\n",
    "idx = idx | idx.shift(1) | idx.shift(-1)\n",
    "\n",
    "heatwave_max_ser = pd.concat(\n",
    "    [\n",
    "        pd.Series(day_mean_ts_ser.loc[g[g].index].mean(), index=g.index)\n",
    "        for i, g in idx.groupby(idx.ne(idx.shift()).cumsum())\n",
    "        if g.any()\n",
    "    ]\n",
    ")\n",
    "date_ser = pd.to_datetime(heatwave_max_ser.rename_axis(\"time\").reset_index()[\"time\"])\n",
    "heatwave_range_df = date_ser.groupby(date_ser.diff().dt.days.ne(1).cumsum()).agg(\n",
    "    start=\"first\", end=\"last\"\n",
    ")\n",
    "# add a day in the end to ensure that we get the data from the start of the first day to\n",
    "# the end of the last day\n",
    "heatwave_range_df[\"end\"] = heatwave_range_df[\"end\"] + datetime.timedelta(days=1)\n",
    "# show the data frame\n",
    "heatwave_range_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Get data from other official stations\n",
    "\n",
    "Download the data from a private S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = official_stations_utils.SpacesClient(bucket_name=bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 2.1 IDAWEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idaweb_ts_df = client.get_idaweb_df(idaweb_key)\n",
    "idaweb_ts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 2.2 Vaud'air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# select the first four columns (the other ones are humidity)\n",
    "vaudair_ts_df = client.get_vaudair_df(vaudair_key).iloc[:, :4]\n",
    "vaudair_ts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 3. Filter heatwaves period, resample and assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "official_ts_df = pd.concat(\n",
    "    [\n",
    "        pd.concat(\n",
    "            [\n",
    "                ts_df.loc[heatwave_start:heatwave_end]\n",
    "                for heatwave_start, heatwave_end in heatwave_range_df.itertuples(\n",
    "                    index=False\n",
    "                )\n",
    "            ],\n",
    "            axis=\"rows\",\n",
    "        )\n",
    "        .resample(\"H\")\n",
    "        .mean()\n",
    "        .rename_axis(\"station\", axis=\"columns\")\n",
    "        .stack()\n",
    "        .rename(\"temperature\")\n",
    "        .reset_index()\n",
    "        for ts_df in [agrometeo_ts_df, idaweb_ts_df, vaudair_ts_df]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# convert to wide format\n",
    "official_ts_df = official_ts_df.pivot_table(\n",
    "    index=\"time\", columns=\"station\", values=\"temperature\"\n",
    ")\n",
    "# add heatwave id as outermost index\n",
    "official_ts_df = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            official_ts_df.loc[start:end].assign(\n",
    "                **{\n",
    "                    \"heatwave\": \"-\".join(\n",
    "                        [\n",
    "                            f\"{date.strftime(STRFMT)}\"\n",
    "                            for date in [start, end - datetime.timedelta(days=1)]\n",
    "                        ]\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "            for start, end in heatwave_range_df.itertuples(index=False)\n",
    "        ]\n",
    "    )\n",
    "    .reset_index()\n",
    "    .set_index([\"heatwave\", \"time\"])\n",
    ")\n",
    "official_ts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Let us now plot, for each heatwave, the hourly temperature averaged over stations and days of the heatwave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for heatwave, heatwave_ts_df in official_ts_df.groupby(level=\"heatwave\"):\n",
    "    heatwave_ts_df = heatwave_ts_df.stack(dropna=True).reset_index(name=\"T\")\n",
    "    sns.lineplot(\n",
    "        heatwave_ts_df.assign(**{\"hour\": heatwave_ts_df[\"time\"].dt.hour}),\n",
    "        x=\"hour\",\n",
    "        y=\"T\",\n",
    "        ax=ax,\n",
    "        label=heatwave,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for heatwave, heatwave_ts_df in official_ts_df.apply(\n",
    "    lambda row: row - min(row), axis=\"columns\"\n",
    ").groupby(level=\"heatwave\"):\n",
    "    heatwave_ts_df = heatwave_ts_df.stack(dropna=True).reset_index(name=\"UHI\")\n",
    "    sns.lineplot(\n",
    "        heatwave_ts_df.assign(**{\"hour\": heatwave_ts_df[\"time\"].dt.hour}),\n",
    "        x=\"hour\",\n",
    "        y=\"UHI\",\n",
    "        ax=ax,\n",
    "        label=heatwave,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 4. Station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "official_stations_gser = official_stations_utils.get_station_gser(\n",
    "    station_location_filepath, station_location_crs\n",
    ")\n",
    "# add missing station locations by hand (TODO: change UGLY hardcoded lines)\n",
    "official_stations_gser[\"Nabel_Lausanne\"] = geometry.Point(2538690, 1152615)\n",
    "# official_stations_gser[\"WSLLAB\"] = geometry.Point(2545761, 1160617)\n",
    "# set CRS lost in line above\n",
    "official_stations_gser = official_stations_gser.set_crs(station_location_crs)\n",
    "# filter to keep only stations in our agglomeration extent\n",
    "official_stations_gser = official_stations_gser[\n",
    "    official_stations_gser.intersects(region.iloc[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot by average temperature\n",
    "plot_kws = {\"legend_kwds\": {\"shrink\": 0.5, \"label\": \"T$_{mean}$ [$\\degree$C]\"}}\n",
    "plot_utils.plot_stations_by_var(\n",
    "    official_stations_gser, official_ts_df.mean().rename(\"T_mean\"), plot_kws=plot_kws\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## 4. Filter data and dump to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations to keep: stations from the time series data and within the extent\n",
    "official_stations = official_stations_gser.index.intersection(official_ts_df.columns)\n",
    "# filter time series data from stations of the region only\n",
    "official_ts_df[official_stations].to_csv(dst_ts_df_filepath)\n",
    "# filter to keep only stations in our time series data frame\n",
    "official_stations_gser.loc[official_stations].to_file(dst_stations_gdf_filepath)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python (uhi-cws-lausanne)",
   "language": "python",
   "name": "uhi-cws-lausanne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
